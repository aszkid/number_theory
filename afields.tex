\section{Algebraic number fields}

It is not a stretch to say that number theory, at least in the classical sense, is about numbers. The study of solutions to equations like $x^2+y^2=z^2$ with ``integer'' coefficients (denoted by $\bbZ$) have concerned number theorists since the Babylonians~\cite{rouseball}. Passing over to the ``rational'' numbers (denoted by $\bbQ$), as ratios of integer parts, is only natural in working with integer equations. Starting with Pythagoras, the Greeks decidedly only worked with rational numbers, and treated ``irrational'' magnitudes as non-existent, as non-numbers (\emph{``He is unworthy of the name of man who is ignorant of the fact that the diagonal of a square is incommesurable with its side''} -- Plato, as quoted by Sophie Germain). While number theory nowadays is still primarily concerned with ``integral'' quantities, mathematics has thankfully moved forward, and the tools of complex analysis and the entire repertoire of numbers (whether real or ``imaginary'') is available to those studying number theoretic questions.

The basic operations of arithmetic in $\bbZ$ (i.e. one can add, subtract, and multiply) are captured in the more general notion of a \emph{ring}. As early as in the 16th century, mathematicians found ``imaginary'' as useful as metaphysically perplexing. One can consider numbers of the form $a+bi$ where $i=\sqrt{-1}$ is the ``imaginary unit'', and show that they not only form a ring; they form an Euclidean domain, admitting unique factorization in prime elements. Gauss used them extensively \todo{citation!}. In other words, we can ``extended'' the usual integers and still preserve essential properties.

Algebra turns this into a rigurous process. We start with the rational numbers, and consider a finite field extension $F$ over $\bbQ$:
\begin{center}
\begin{tikzcd}
		& F \\
	\bbZ \arrow[r] & \bbQ \arrow[u]
\end{tikzcd}
\end{center}
(arrows denote inclusion for now). Previously, we formed ``fractional'' elements $\bbQ$ from $\bbZ$: now we would like to restrict our attention to ``integral'' elements of $F$, i.e. forming ``$\bbZ$'' from ``$\bbQ$''. If we can define such a notion that works for $\bbQ$, that will suffice. For example, consider polynomials of degree one with coefficients in $\bbZ$, i.e. $x+a=0$ with $a\in\bbZ$. The solutions to these equations in $\bbQ$ are exactly the elements of $\bbZ$: in fact, considering polynomials with higher degree yields no other solutions in $\bbQ$. We say that the \emph{integral closure} of $\bbZ$ in $\bbQ$ is, again, $\bbZ$.

In the general case, we go back to our finite extension $F$ and consider monic polynomials
\[
	x^n + a_1x^{n-1} + \cdots + a_{n-1}x + a_n = 0
\]
with coefficients $a_i\in\bbZ$. We say that an element $y\in F$ is \emph{integral} if it solves such a polynomial, and call the set of integral elements of $F$ the \emph{integral closure} of $\bbZ$ in $F$, denoted by $\calO_F$. The diagram above becomes

\begin{center}
\begin{tikzcd}
	\calO_F \arrow[r] & F\\
	\bbZ \arrow[u] \arrow[r] & \bbQ \arrow[u].
\end{tikzcd}
\end{center}

It requires some work to show that if $F=\bbQ(i)$, then its integral closure is $\calO_F=\bbZ[i]$ (the usual Gaussian integers), so that our definition does make sense.

To what extend $\calO_F$ is a good generalization of the usual integers $\bbZ$ is the guiding thread of this paper. In particular, we will ask

\begin{quest}
	Does unique factorization hold in $\calO_F$?
\end{quest}

and, from a more algebraic point of view,

\begin{quest}
	What are the units of $\calO_F$?
\end{quest}


\subsection{Modules and integrality}

The question of integrality is fundamental in the study of number fields, and it proves fruitful to develop the theory in its full generality.

For a given ring extension $A\subseteq B$, we say that $B$ is \emph{integral over $A$} if each element in $B$ is integral over $A$. Integral elements of $B$ give the $A$-modules they generate a good structure property.

\begin{prop}[Neukirch 2.2]
	Finitely many elements $b_1,\dots,b_n\in B$ are integral over $A$ iff the $A$-module $A[b_1,\dots,b_n]$ is finitely generated.
\end{prop}
\begin{proof}
	($\Longrightarrow$) Start by assuming that $b\in B$ is integral over $A$. Then $f(b)=0$ for some polynomial $f(x)$ over $A$. Now let $g(x)\in A[x]$: by the division algorithm, we have $g(x)=q(x)f(x)+r(x)$ with polynomials over $A$ and $\deg r(x) < \deg q(x)$.

	In particular, passing to $A[b]$, we have $g(b)=r(b)=a_0+a_1b+\cdots+a_{n-1}b^{n-1}$. So any element in $A[b]$ is generated by $\{1,b,\dots,b^{n-1}\}$, i.e. $A[b]$ is finitely generated.

	Now assume that $R=A[b_1,\dots,b_{n-1}]$ is finitely generated for $b_1,\dots,b_n\in B$ integral over $A$. The same argument shows that $R[b_n]$ is finitely generated too, since $b_n$ is integral over $A$ and hence over $R$ as well. Induction proves the result.

	($\Longleftarrow$) Now assume that $A[b_1,\dots,b_n]$ is finitely generated. Let $\omega_1,\dots,\omega_r$ be a system of generators. Take any $b\in A[b_1,\dots,b_n]$; we have $\omega_i A[b_1,\dots,b_n] \subseteq A[b_1,\dots,b_n]$, so in particular $\omega_i b = a_{i1}\omega_1 + \cdots + a_{ir}\omega_r$ for each $1\leq i \leq r$. Rearranging the equations we get a system
	\begin{align*}
		(b-a_{11})\omega_1 + \cdots + (-a_{1r})\omega_r &= 0\\
		\vdots &= 0\\
		(-a_{i1})\omega_1 + \cdots + (b-a_{ii})\omega_i + \cdots + (-a_{ir})\omega_r&=0\\
		\vdots &= 0\\
		(-a_{r1})\omega_1 + \cdots + (b-a_{rr})\omega_r &= 0
	\end{align*}
	In matrix form we can write the coefficients as $bI - (a_{ij})$, and we have that the vector of generators solves the system, i.e. $(bI-(a_{ij}))\omega_i = 0$, so $\det(bI-(a_{ij}))\omega_i = 0$, but $\omega_i\neq 0$ so necessarily $\det(bI-(a_{ij}))=0$. This gives a polynomial over $A$ for which $b$ is a root, so $b$ is integral over $A$.
\end{proof}

Compare this result to an arbitrary ring extension, which is not necessarily finitely generated as an $A$-module, just like the polynomial ring $A[x]$.

\begin{prop}
	Let $A\subseteq B\subseteq C$ be ring extensions. If $B$ is integral over $A$ and $C$ is integral over $B$, then $C$ is integral over $A$.
\end{prop}
\begin{proof}
	Fix $c\in C$: since $C$ is integral over $B$, we have an equation $c^n+b_1c^{n-1}+\cdots+b_n=0$ with coefficients in $B$. In particular $R=A[b_1,\dots,b_n]$ is finitely generated because $B$ is integral over $A$. As an $R$-module, $R[c]$ is finitely generated since $c$ is integral over $B$. Since $B$ is integral over $A$, then $R[c]$ is furthermore finitely generated over $A$ by each $b_i$ being integral over $A$. Hence $c$ is integral over $A$.
\end{proof}

We call the set $\overline{A}=\{b\in B \mid b \text{ integral over } A\}$ the \emph{integral closure of $A$ in $B$}, and say that $A$ is \emph{integrally closed} if $A=\overline{A}$. Note that $A$ is trivially integral over $A$ because $a\in A$ is a solution to the monic polynomial $x-a=0$, hence $A\subset\overline{A}$. This gives a chain $A\subset \overline{A}\subset\overline{\overline{A}}$ of integral closures, and applying the previous proposition we get that $\overline{\overline{A}}$ is integral over $A$, so $\overline{\overline{A}}\subset\overline{A}$. The two inclusions imply that $\overline{A}=\overline{\overline{A}}$, i.e. $\overline{A}$ is integrally closed, so it makes sense to call it \emph{the} integral closure of $A$.


\subsection{Trace and norm}

Consider a finite field extension $L\mid K$. The following concepts will prove useful in studying the integral elements of $L$.\todo{Is it so?}

\begin{defn}
	The \emph{trace} and \emph{norm} of some $x\in L$ are defined as the trace and norm of the matrix $[T_x]$ representing the endomorphism $T_x:L\to L$ given by $T_x(\alpha)=x\alpha$, i.e.
	\begin{align*}
		\Tr_{L\mid K}(x) = \Tr([T_x]) & & \N_{L\mid K}(x) = \det([T_x]).
	\end{align*}
\end{defn}

We only need to compute the action of trace and norm on some basis to get the field trace and norm: for example, with $K=\bbR$ and $L=\bbC$, we have a the usual basis $\{1,i\}$ for $\bbC$, and so for any $z=a+bi\in\bbC$ we get $T_z(1)=a+bi$ and $T_z(i)=-b+ai$. This gives the matrix
\[
	\begin{bmatrix}
		a & -b\\
		b & a
	\end{bmatrix},
\]
the trace and norm of which are $2a$ and $a^2+b^2$.

\begin{prop}
	The trace $\Tr_{L\mid K}$ is a $K$-linear additive homomorphism $L\to K$, and the norm $\N_{L\mid K}$ is a \todo{Also K-linear?}multiplicative homomorphism $L^\times\to K^\times$.
\end{prop}
\begin{proof}
	This amounts to passing to matrix representations as needed.

	First of all, it is clear that $T_{x+y}=T_x+T_y$, and $T_{xy}=T_x\circ T_y$. Now pick a basis for $L\mid K$ and find the matrix representations of $T_x$ and $T_y$. We have that
	\begin{align*}
		\Tr_{L\mid K}(x+y)=\Tr([T_{x+y}])&=\Tr([T_x+T_y])\\
			&=\Tr([T_x])+\Tr([T_y])\\
			&= \Tr_{L\mid K}(x)+\Tr_{L\mid K}(y),
	\end{align*}
	so the field trace is at least additive, just like the usual trace.

	Similarly, we have
	\begin{align*}
		\N_{L\mid K}(xy) = \det([T_{xy}]) &= \det([T_x][T_y])\\
			&= \det([T_x])\det([T_y])\\
			&= \N_{L\mid K}(x)\N_{L\mid K}(y),
	\end{align*}
	so the field norm is multiplicative, just like the usual norm.

	For $K$-linearity of the trace, fix $c\in K$ and $x\in L$: as an endomorphism, we have $T_{cx}(\alpha)=c T_x(\alpha)$, so
	\begin{align*}
		\Tr_{L\mid K}(cx) = \Tr([T_{cx}]) &= \Tr(c[T_x])\\
			&= c\Tr([T_x])\\
			&= c \Tr_{L\mid K}(x).
	\end{align*}

	And additivity extends this to finitely many terms, so the trace is $K$-linear.
\end{proof}




Given $n=[L : K]$, the characteristic polynomial of $T_x$ is
\[
	f_x(t) = \det(tI - [T_x]) = t^n - a_1t^{n-1} + \cdots + (-1)^na_n.
\]
Note that $a_1=\Tr_{L\mid K}(x)$ and $a_n=\N_{L\mid K}(x)$\todo{Not obvious!}, and the degree of $f_x(t)$ is always fixed relative to $L\mid K$.

On the other hand, the minimal polynomial $p_x(t)$ of any $x\in L$ over $K$ has degree $[K(x) : K]$, which depends of course on the choice of $x$.



We now study the close interplay between the characteristic and the minimal polynomial.

\begin{prop}
	Every $x \in L$ is a root of the characteristic polynomial of $T_x$.
\end{prop}
\begin{proof}
	This follows from Cayley-Hamilton: considering $f_x$ as a linear operator, evaluating at the matrix $[T_x]$ is zero by definition, but we can expand it with addition being usual matrix addition, and powers being repeated matrix multiplication. Then
	\begin{align*}
		0 = f_x([T_x]) &= [T_x]^n - a_1[T_x]^{n-1} + \cdots + (-1)^na_n I\\
			&= [T_{x^n}] - a_1[T_{x^{n-1}}] + \cdots + (-1)^na_n I\\
			&= [T_{x^n}] - [T_{a_1x^{n-1}}] + \cdots + (-1)^na_n I\\
			&= [T_{x^n-a_1x^{n-1} + \cdots + (-1)^na_n}]\\
			&= [T_{f_x(x)}],
	\end{align*}
	which implies that $T_{f_x(x)}=0$, i.e. $f_x(x)=0$.
\end{proof}

\begin{prop}
	Fix $x\in L$, let $p_x(t)$ be the minimal polynomial of $x$ and $f_x(t)$ the characteristic polynomial of $T_x$. Then
	\[
		f_x(t) = (p_x(t))^{n/d},
	\]
	where $n=[L:K]$ and $d=[K(x):K]$.
\end{prop}
\begin{proof}
	Fix $x\in L$. The set $\{x,x^2,\dots,x^{d-1}\}$ is a basis of $K(x)\mid K$. Pick a basis $\{\alpha_1,\dots,\alpha_m\}$ of $L\mid K(x)$. The set 
	\[
		\{\alpha_1, \alpha_1 x,\alpha_1 x^2, \dots, \alpha_1 x^{d-1}; \alpha_2, \alpha_2 x, \alpha_2 x^2, \dots, \alpha_2 x^{d-1}; \dots ; \alpha_m, \alpha_m x, \dots, \alpha_m x^{d-1}\}
	\]
	is a basis for $L\mid K$.

	We write $T_x$ as a matrix with respect to this basis. Let $e_{ij}$ be the basis vectors of $L$, i.e. $e_{01} = \alpha_1 = (1,0,\dots,0)$, $e_{11} = x \alpha_1 = (0,1,\dots,0)$, etc. Note that for $i<d-1$ we have
	\begin{align*}
		T_x(e_{ij}) = x e_{ij} &= x x^i \alpha_j\\
			&= x^{i+1} \alpha_j\\
			&= e_{(i+1)j},
	\end{align*}
	and for $i=d-1$
	\begin{align*}
		T_x(e_{(d-1)j}) = x^d \alpha_j,
	\end{align*}
	but since $\{x^i\}_{0\leq i \leq d-1}$ is a basis for $K(x)$ we must have some linear combination 
	\begin{align*}
		c_d + x c_{d-1} + \cdots + x^{d-1} c_1 + x^d = 0,
	\end{align*}
	which is in fact the minimal polynomial of $x$ since $d=[K(x):K]$. Hence $T_x(e_{(d-1)j}) = \alpha_j (-c_d - x c_{d-1} - \cdots - x^{d-1} c_1)$.
	
	We have just shown that $T_x$ gives the same matrix for each subspace generated by $\{e_{ij}\}_{0\leq j\leq m}$:
	\[
	\begin{pmatrix}
		0 & 1 & 0 & \cdots & 0\\
		0 & 1 & 1 & \cdots & 0\\
		\cdots & \cdots & \cdots & \cdots & \cdots\\
		0 & 0 & 0 & \cdots & 1\\
		-c_d & -c_{d-1} & -c_{d-2} & \cdots & -c_1
	\end{pmatrix},
	\]
	so to compute the characteristic polynomial of $[T_x]$ it suffices to compute it for the block above. This can be done by using the permutation formula of the determinant\todo{Show work}, which gives
	\[
		t^d + c_1 t^{d-1} + \cdots + c_{d-1} t + c_d = p_x(t).
	\]

	By $[T_x]$ consisting of $m$ identical blocks with determinant $p_x(t)$, we get $f_x(t)=p_x(t)^m$.

\end{proof}

Note that if $L=K(x)$, we have that $f_x(t)=p_x(t)$.


A special form for field trace and norm can be given if $L\mid K$ is a separable extension. Let $d=[L:K(x)]$ and $m=[K(x):K]$, so $[L:K]=dm$.

\begin{prop}
	Given a separable field extension $L\mid K$ and $\sigma : L\to\overline{K}$ a $K$-embedding of $L$, we have
	\begin{enumerate}[(i)]
		\item $f_x(t)= \prod_\sigma(t-\sigma x)$,
		\item $\Tr_{L\mid K}(x) = \sum_\sigma \sigma x$, and
		\item $\N_{L\mid K}(x) = \prod_\sigma \sigma x$.
	\end{enumerate}
\end{prop}
\begin{proof}
	Since $L\mid K$ is separable, $x\in L$ is separable, so there are exactly $m$ $K$-embedding $\tilde{\sigma}:K(x)\to \overline{K}$. Each of these extends to a $K$-embedding $\sigma: L\to \overline{K}$ in $d$ different ways. Since $[L:K]_s=md$, this accounts for all $K$-embeddings $L\to\overline{K}$. Hence we can split $\Hom_K(L,\overline{K})$ into $m$ equivalence classes by identifying $\sigma \sim \tau$ if $\sigma(x)=\tau(x)$ (corresponding to choice of $x^\sigma$); each of the equivalence classes has $d$ distinct embeddings.

	%(Another argument: $L$ is a finite extension over $K(x)$, so any element in $L$ can be written as a linear combination of $d$ basis elements in $L$ with coefficients in $K(x)$. A $K$-embedding of $L$ into $\overline{K}$ must decide where $x$ goes (exactly $m$ choices, the degree of $p_x(t)$) and where the $d$ elements of the basis of $L$ go.)

	Hence, taking representatives $\sigma_1,\dots,\sigma_m$, we have
	\begin{align*}
		p_x(t) = \prod_{i=1}^m (t- \sigma_i x),
	\end{align*}
	and by the previous proposition,
	\begin{align*}
		f_x(t) &= \left( p_x(t)\right)^d\\
			&= \left(\prod_{i=1}^m (t-\sigma_i x)\right)^d\\
			&= \prod_\sigma (t-\sigma x),
	\end{align*}
	the last equality being valid since any two embeddings in the same equivalence class agree on $x$.

	Recall the block form of $[T_x]$. Summing along the diagonal gives $-c_1$, which by Vieta is equal to the sum of the roots of $p_x(t)$, i.e. $\sum_{i=1}^m \sigma_i x$. Again, the block is repeated $d$ times, so we have
	\begin{align*}
		\Tr_{L\mid K}(x) &= d \sum_{i=1}^m \sigma_i x\\
			&= \sum_\sigma \sigma x.
	\end{align*}

	Computing the determinant of $[T_x]$ by the permutation formula gives
	\begin{align*}
		\N_{L\mid K} &= \sum_\sigma \sigma x.
	\end{align*}

\end{proof}

The trace and norm behave well as we take field extensions:

\begin{cor}
	Given a tower of finite field extensions $K\subset L\subset M$, we have
	\begin{align*}
		\Tr_{L\mid K} \circ \Tr_{M\mid L} = \Tr_{M\mid K}, & & \N_{L\mid K} \circ \N_{M\mid L} = \N_{M\mid K}.
	\end{align*}
\end{cor}
\begin{proof}
	Using a similar technique as in the proposition above, we partition $\Hom_K(M,\overline{K})$ into $m=[L:K]$ equivalence classes by identifying $\sigma\sim\tau$ if $\sigma|_L = \tau|_L$. Take a system of representatives $\sigma_1,\dots,\sigma_m$: then $\Hom_K(L,\overline{K}) = \{\sigma_i|_L , 1\leq i \leq m\}$.

	Fix $x\in M$. We have
	\begin{align*}
		\Tr_{M\mid K}(x) &= \sum_\sigma \sigma x\\
			&= \sum_{i=1}^m \sum_{\sigma\sim\sigma_i} \sigma x\\
			&= \sum_{i=1}^m \Tr_{\sigma_i M\mid \sigma_i L}(\sigma_i x)\\
			&= \sum_{i=1}^m \sigma_i \Tr_{M\mid L}(x)\\
			&= \Tr_{L\mid K}(\Tr_{M\mid L}(x)).
	\end{align*}
	\todo{Develop third equality.}

\end{proof}


Given a basis $\alpha_1,\dots,\alpha_n$ of a separable field extension $L\mid K$, we define its \emph{discriminant} by
\[
	d(\alpha_1,\dots,\alpha_n) = \det((\sigma_i\alpha_j))^2,
\]
where $\sigma_i$ varies over $K$-embeddings $L\to\overline{K}$.\todo{Write discriminant in terms of trace and in the special case of a simple extension.}


\begin{prop}
	If $L\mid K$ is separable and $\alpha_1,\dots,\alpha_n$ is a basis for $L$, we have that $d(\alpha_1,\dots,\alpha_n)\neq 0$ and $(x,y) \to \Tr_{L\mid K}(xy)$ is a nondegenerate bilinear form on $L$ as a $K$-vector space.
\end{prop}
\begin{proof}
	A routine computation shows that $(x,y)$ is indeed linear on each coordinate.

	Recall that a bilinear form $(x,y)$ can be expressed by a matrix $M$, so that $(x,y) = x^T M y$. Non-degeneracy is equivalent to requiring $\det(M)\neq 0$.
	
	Since $L\mid K$ is separable, the primitive element theorem gives some $\theta\in L$ for which $L=K(\theta)$. Hence
	\[
		\det(M) = \prod_{i<j}(\theta_i-\theta_j)^2 \neq 0,
	\]
	since otherwise $\theta_i = \theta_j$, implying that $\sigma_i=\sigma_j$, a contradiction.

	Denote the bilinear form $(x,y)$ with respect to some other basis $\alpha_1,\dots,\alpha_n$ by $M'$. Using a change of basis, we have $M=SM'S\inv$. Take the determinant on both sides to get $0\neq\det(M)=\det(S)\det(M')\det(S\inv)=\det(M')$.
\end{proof}



\subsection{Integrality continued -- integral bases}


The main use of integrality we care about in this presentation concerns the ring of integers $\calO_K$ of some algebraic number field $K$. 

We remind ourselves of the usual setup: we have an integrally closed integral domain $A$, its field of fractions $K$, a finite separable extension $L\mid K$, and the integral closure $B$ of $A$ in $L$. The classical equivalent is given by $A=\bbZ$, $K=\bbQ$, $L$ a quadratic or cyclotomic extension, etc., and $B=\calO_K$ the ring of integers.

Note that $x\in B$ implies that all its conjugates $\sigma x$ are integral in $L$ too. Hence $\Tr_{L\mid K}(x)$ and $\N_{L\mid K}(x)$ are in $A$\todo{Elaborate. Use $A=B\cap K$.}.

\begin{lem}
	If $\alpha_1,\dots,\alpha_n$ is a basis of $L\mid K$ contained in $B$, of discriminant $d=d(\alpha_1,\dots,\alpha_n)$, we have
	\[
		dB\subseteq A\alpha_1 + \cdots + A\alpha_n.
	\]
\end{lem}
\begin{proof}
	Fix $\alpha\in B$. We have $\alpha=a_1\alpha_1+\cdots+a_n\alpha_n$ with $a_j\in K$. Taking the trace of both sides of the equality multiplied by $\alpha_i$, we get
	\begin{align*}
		\Tr_{L\mid K}(\alpha_i \alpha) &= \Tr_{L\mid K}(a_1\alpha_1+\cdots+a_n\alpha_n)\\
			&= \sum_{j=1}^n \Tr_{L\mid K}(\alpha_i\alpha_j) a_j,
	\end{align*}
	this last equality by $\Tr$ being additive and $K$-linear. This gives a system of $n$ linear equations for which the $a_j$ are a solution. In fact, since the trace evaluated at elements in $B$ lands in $A$, this is a system with coefficients in $A$; say $Mx=b$.

	The determinant of $M=(\Tr_{L\mid K}(\alpha_i\alpha_j))$ is exactly $d$, so we have
	\begin{align*}
		x &= M\inv b\\
		  &= \det(M)\inv\adj(M)b.
	\end{align*}
	
	Hence we can write $a_j$ as a quotient of some element in $A$ by $d$, i.e. $da_j\in A$. Therefore $d\alpha\in A\alpha_1+\cdots+A\alpha_n$.
\end{proof}

This setup, a system $\omega_1,\dots,\omega_n\in B$ that serves as a basis for $B$ over $A$ proves useful: we say that $\{\omega_j\}$ forms an \emph{integral basis} of $B$ over $A$. Note that such a basis immediately gives a basis of $L\mid K$ (for $L$ is the field of fractions of $B$\todo{Elaborate. Easy argument.}), which forces our integral basis to be of length $[L:K]$. In particular, if $B$ admits an integral basis, we can consider $B$ as a free $A$-module or rank $[L:K]$.

For most of our upcoming work, we require $A$ to be a principal ideal domain. This nicely classifies $B$-submodules of $L$.

\begin{prop}
	If $L\mid K$ is separable and $A$ is a PID, then every finitely generated $B$-submodule $M\neq 0$ is a free $A$-module of rank $[L:K]$.
\end{prop}
\begin{proof}
	Let $M\neq 0$ be a finitely generated $B$-submodule of $L$ and $\alpha_1,\dots,\alpha_n$ a basis of $L\mid K$. We want to apply the previous theorem, but first need to somehow shift the basis to lie in $B$. Fix $\alpha_i$; we have some monic polynomial $p(x)$ with coefficients $a_j$ in $K$ for which $\alpha_i$ is a root. Let $l$ be the product of all the denominators of the $a_j$, so that
	\begin{align*}
		l^n p(\alpha) = l^n \alpha_n + l^n a_1 \alpha^{n-1} + \cdots + l^n a_n = 0.
	\end{align*}

	Now consider the monic polynomial
	\begin{align*}
		q(x) = x^n + l a_1 x^{n-1} + \cdots + l^n a_n,
	\end{align*}
	which has coefficients in $A$ (denominators cancel thanks to $l$). This polynomial has $l\alpha$ as a root, which implies that $l\alpha$ is integral over $A$, that is $l\alpha\in B$. We repeat this procedure for each element of the basis, and hereafter refer to this new basis simply as $\alpha_j\in B$.

	Hence, with $d=d(\alpha_1,\dots,\alpha_n)$, we have $dB\subseteq A\alpha_1+\cdots+A\alpha_n$. In the language of modules, we have that $dB$ is a submodule of the free module $A_1\alpha_1\oplus\cdots\oplus A_n\alpha_n$. In particular, $A$ is a PID, so it is noetherian, and therefore $dB$ is a torsion-free finitely generated module. Since $dB$ has no torsion part, by the classification theorem of finitely generated modules over PIDs it is necessarily a free module of rank $m \leq n = [L:K]$.

	Now notice that having a system of generators $\alpha_j$ for $B$ as an $A$-module implies that we also have a system of generators for $L$ as a $K$-module. In fact, we have $dB=A\beta_1\oplus\cdots\oplus A\beta_m$ with $\beta_j\in dB$, hence $\frac{\beta_j}{d}\in B$. Now let $b\in B$, so that
	\begin{align*}
		db &= b_1\beta_1 + \cdots + b_m\beta_m\\
		b &= b_1\frac{\beta_1}{d} + \cdots + b_m\frac{\beta_m}{d}
	\end{align*}
	with $b_j\in A$. This shows that the rank of $B$ is also $m$, i.e. $\rank(B)\leq[L:K]$. The same argument as in the previous lemma shows that a system of the same length generates $L$ as a $K$-module, which forces $\rank(B)=[L:K]$. Now choose a system $\mu_1,\dots,\mu_r\in M$ of generators of the $B$-module $M$. Again, we can choose some $a_i\in A$ for which $a_i\mu_i\in B$; in fact, letting $a=a_1\cdots a_n$ we get a single element for which $a\mu_i\in B$ for all $i$. Hence $aM\subseteq B$, so that
	\[
		adM \subseteq dB \subseteq M_0
	\]
	with $M_0=A\alpha_1\oplus\cdots\oplus A\alpha_n$. By the same classification theorem, $M_0$ being a free $A$-module implies that $adM$ is one as well, hence also $M$. Putting everything together, we get
	\begin{align*}
		[L:K] = \rank(B) &\leq \rank(M)\\
			&= \rank(adM)\\
			&\leq \rank(M_0) = [L:K],
	\end{align*}
	that is $\rank(M)=[L:K]$.
\end{proof}

Looking back to the usual integral closure $\calO_K\subset K$ of $\bbZ\subset\bbQ$ in some algebraic number field $K$, the immediate application of these results on integral bases gives every finitely generated $\calO_K$-submodule $\fraka$ of $K$ a $\bbZ$-basis $\alpha_1,\dots,\alpha_n$, i.e. $\fraka = \alpha_1\bbZ+\cdots+\alpha_n\bbZ$. Since the discriminant $d(\alpha_1,\dots,\alpha_n)$ is independent of our choice of $\bbZ$-basis, we can simply write $d(\fraka)=d(\alpha_1,\dots,\alpha_n)$.

In particular, given an integral basis $\omega_1,\dots,\omega_n$ of $\calO_K$, we define the \emph{discriminant of the algebraic number field $K$} as
\[
	d_K = d(\calO_K) = d(\omega_1,\dots,\omega_n).
\]


The following proposition that relates two $\calO_K$-submodules will be useful later.

\begin{prop}
	If $\fraka\subseteq\fraka'$ are two non-zero finitely generated $\calO_K$-submodules of $K$, then the index $(\fraka:\fraka')$ is finite and satisfies
	\[
		d(\fraka) = (\fraka:\fraka')^2 d(\fraka').
	\]
\end{prop}
\begin{proof}
	As $\bbZ$-modules, $\fraka$ and $\fraka'$ have the same rank (by classification theorem). Let $A$ denote the change of basis matrix from a $\bbZ$-basis $\calB$ of $\fraka'$ to a $\bbZ$-basis $\calC$ of $\fraka$. By the Smith normal form, we get invertible matrices $P$ and $Q$ such that $PAQ$ is diagonal. Write $\calB'=Q\inv\calB$ and $\calC'=P\calC$, bases of $\fraka'$ and $\fraka$ respectively. It follows that $\calB'$ and $\calC'$ are stacked, so
	\[
		\fraka'/\fraka \cong \bbZ_{d_1} \oplus \cdots \oplus \bbZ_{d_n},
	\]
	with $d_i$ the diagonal entries of $PAQ$, hence $|\det(A)|=d_1\cdots d_n=(\fraka:\fraka')$. Therefore
	\begin{align*}
		d(\fraka) &= \det(A)^2 d(\fraka')\\
			&= (\fraka:\fraka')^2 d(\fraka').
	\end{align*}
\end{proof}
